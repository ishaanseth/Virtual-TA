# TDS Virtual TA Project

This project implements a Virtual Teaching Assistant for the "Tools in Data Science" course. It uses a FastAPI backend, scrapes course content and Discourse forum posts, generates embeddings, and uses a Large Language Model (LLM) via AI Pipe to answer student questions based on the retrieved context.

## Features

- Scrapes course content from the official course website.
- Scrapes relevant posts from the TDS Discourse forum within a specified date range.
- Generates text embeddings for all scraped content.
- Provides a FastAPI endpoint (`/api/`) to answer questions.
- Uses a RAG (Retrieval Augmented Generation) approach:
  - Finds relevant documents using semantic similarity (cosine similarity on embeddings).
  - Augments context by fetching subsequent replies for relevant Discourse posts.
  - Sends the question and retrieved context to an LLM (via AI Pipe) for answer generation.
- Configured for evaluation with `promptfoo`.

## Project Structure

```
.
├── main.py                          # FastAPI application
├── scrapers/
│   ├── new_course.py               # Selenium-based course content scraper
│   └── new_discourse.py            # Discourse forum scraper
├── course_content.json             # Generated by new_course.py (if run)
├── discourse_posts_v2.json         # Generated by new_discourse.py (if run)
├── content_embeddings.json         # Generated by main.py on first startup
├── requirements.txt                # Python dependencies
├── Dockerfile                      # For containerizing the application
├── .env.example                    # Example environment variables
├── .env                            # Local environment variables (DO NOT COMMIT)
├── project-tds-virtual-ta-promptfoo.yaml  # Promptfoo evaluation configuration
├── README.md
└── LICENSE                         # MIT License
```

## Setup and Installation

### 1. Clone the Repository:
```bash
git clone <your-repository-url>
cd <your-repository-name>
```

### 2. Create and Activate a Python Virtual Environment:
```bash
python -m venv .venv
# On Windows
.\.venv\Scripts\activate
# On macOS/Linux
source .venv/bin/activate
```

### 3. Install Dependencies:
- Ensure Google Chrome is installed.
- Install packages:
```bash
pip install -r requirements.txt
```

### 4. Set Up Environment Variables:
- Copy `.env.example` to `.env`:
```bash
# Windows
copy .env.example .env
# macOS/Linux
cp .env.example .env
```
- Edit `.env`:
```env
AIPIPE_TOKEN="your_actual_aipipe_token_here"
OPENAI_API_BASE_FOR_EMBEDDINGS="https://aipipe.org/openai/v1"
OPENROUTER_API_BASE_FOR_CHAT="https://aipipe.org/openrouter/v1"
EMBEDDING_MODEL_NAME="text-embedding-3-small"
CHAT_MODEL_NAME="google/gemini-flash-1.5"
```

### 5. Prepare Data (Scraping):
- If using pre-scraped files, place `course_content.json` and `discourse_posts_v2.json` in root.
- **To re-scrape:**
  - **Discourse Scraper:**
    ```bash
    python scrapers/new_discourse.py
    ```
  - **Course Content Scraper:**
    ```bash
    python scrapers/new_course.py
    ```

## Running the Application

### 1. Activate Virtual Environment:
```bash
# Windows
.\.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
```

### 2. Start FastAPI Server:
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 3. First-Time Embedding Generation:
- On first run, `content_embeddings.json` will be created (can take time).
- Subsequent runs will reuse it.

### 4. Access the API:
```
http://127.0.0.1:8000/api/
```

## Sending Queries to the API

### Example with `curl`:
```bash
curl -X POST -H "Content-Type: application/json" -d '{"question": "What are development tools?"}' http://127.0.0.1:8000/api/
```

### Example with PowerShell:
```powershell
Invoke-RestMethod -Uri http://127.0.0.1:8000/api/ -Method Post -ContentType "application/json" -Body '{"question": "What are development tools?"}'
```

### Request Body Format:
```json
{
  "question": "Your question string here",
  "image": "base64_encoded_image_string_or_null"
}
```

### Response Format:
```json
{
  "answer": "The LLM-generated answer based on context.",
  "links": [
    {
      "url": "source_document_url_1",
      "text": "Title or description of source_document_1"
    },
    {
      "url": "source_document_url_2",
      "text": "Title or description of source_document_2"
    }
  ]
}
```

## Running Evaluations with `promptfoo`

### 1. Set Environment Variables:

#### PowerShell:
```powershell
$env:AIPIPE_TOKEN="your_actual_aipipe_token"
$env:OPENAI_API_KEY=$env:AIPIPE_TOKEN
$env:OPENAI_BASE_URL="https://aipipe.org/openai/v1"
```

#### Bash:
```bash
export AIPIPE_TOKEN="your_actual_aipipe_token"
export OPENAI_API_KEY=$AIPIPE_TOKEN
export OPENAI_BASE_URL="https://aipipe.org/openai/v1"
```

### 2. Run Evaluation:
```bash
npx -y promptfoo eval --config project-tds-virtual-ta-promptfoo.yaml --no-cache
```

### 3. View Results:
```bash
npx -y promptfoo view
```

## Deployment (Temporary Public URL using `ngrok`)

- Ensure FastAPI server is running.
- Download ngrok from [ngrok.com](https://ngrok.com/).
- Authenticate:
```bash
.
grok.exe authtoken YOUR_NGROK_AUTHTOKEN
```
- Start:
```bash
.
grok.exe http 8000
```

Use the generated public HTTPS URL for promptfoo or submissions.

### Permanent Deployment Options:
Consider Google Cloud Run, PythonAnywhere, etc. You may use the provided Dockerfile.

## Project Structure for GitHub Submission

### Include:
- `main.py`, `scrapers/`, `requirements.txt`, `Dockerfile`
- `.env.example`, `project-tds-virtual-ta-promptfoo.yaml`
- `README.md`, `LICENSE`

### Exclude:
Use `.gitignore` to exclude:
- `.env`, `.venv/`, `__pycache__/`
- `content_embeddings.json`
- Large `course_content.json` or `discourse_posts_v2.json`

Optionally include small samples of the data JSONs.

## Troubleshooting

- **Embedding Failures:** Check `AIPIPE_TOKEN`, quota, API errors.
- **promptfoo Errors:**
  - `OPENAI_API_KEY not set`: Ensure relevant env vars are exported.
  - `File not found`: Ensure test image exists in project root.
- **CORS Errors:** Check CORSMiddleware config in `main.py`.
- **Cloud Run Issues:** Check logs for dependency, memory, or env var problems.

---

**Notes:**
- Replace `<your-repository-url>` and `<your-repository-name>`.
- Adjust scraper or model names as needed.
- Validate GitHub submission file sizes and exclusions.
